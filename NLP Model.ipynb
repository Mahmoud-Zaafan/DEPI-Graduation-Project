{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task Classification Using Machine Learning Algorithms</h2>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Importing the libraries<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,  precision_recall_fscore_support\n",
    "from tabulate import tabulate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Importing dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_csv('task_dataset.csv')[['input', 'label']]\n",
    "\n",
    "X = dataset.iloc[:, 0].values.astype('U')\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Some insights about the dataset </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Define a function for text preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Word tokenization\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words_en = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words_en]\n",
    "\n",
    "    # Stemming (we will not use it in the project)\n",
    "    # from nltk.stem import PorterStemmer\n",
    "    # from nltk.stem.isri import ISRIStemmer\n",
    "    # stemmer_en = PorterStemmer()\n",
    "    # stemmer_ar = ISRIStemmer()\n",
    "    # text = [stemmer_en.stem(stemmer_ar.stem(word)) for word in text]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word, pos='v') for word in text]  # consider all words as verbs\n",
    "    text = [lemmatizer.lemmatize(word, pos='a') for word in text]  # consider all words as adjectives\n",
    "\n",
    "    # pos_tags = nltk.pos_tag(text)\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # text = [\n",
    "    #     lemmatizer.lemmatize(word, pos=pos[0].lower()) if pos[0].lower()\n",
    "    #     in ['a', 'r', 'n', 'v'] else lemmatizer.lemmatize(word)\n",
    "    #     for word, pos in pos_tags\n",
    "    # ]\n",
    "    \n",
    "    # Concatenate tokens\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Make text preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X = []\n",
    "processed_y = []\n",
    "\n",
    "# Iterate over each sample in X and y\n",
    "for text, label in zip(X, y):\n",
    "    processed_text = text_preprocessing(text)\n",
    "    # Check if the processed text is not already in processed_X\n",
    "    if processed_text not in processed_X:\n",
    "        # If not, append the processed text to processed_X and the corresponding label to processed_y\n",
    "        processed_X.append(processed_text)\n",
    "        processed_y.append(label)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "processed_X = np.array(processed_X)\n",
    "processed_y = np.array(processed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['currency wallet', 'tell currency palm', 'identify money hand',\n",
       "       'whats denomination bill im hold', 'tell type currency hand',\n",
       "       'describe currency note im touch', 'recognize bill im feel',\n",
       "       'money', 'detect currency possession', 'identify banknote im hold',\n",
       "       'whats front', 'describe scene front', 'see surround',\n",
       "       'tell environment front', 'describe whats happen around',\n",
       "       'whats visible position', 'give description current surround',\n",
       "       'object field view', 'whats around', 'far door',\n",
       "       'determine distance door', 'whats depth door',\n",
       "       'measure distance door', 'estimate gap door',\n",
       "       'calculate distance door', 'much space door', 'find distance door',\n",
       "       'whats distance door', 'read text front', 'read', 'translate text',\n",
       "       'say', 'extract text image', 'whats write paper',\n",
       "       'read word document', 'decode text image', 'convert image text',\n",
       "       'translate text english', 'convert english', 'change english',\n",
       "       'translate english', 'whats english version text',\n",
       "       'convert english language', 'provide english translation',\n",
       "       'change language english', 'color car front', 'describe color car',\n",
       "       'whats color vehicle', 'identify color nearby car',\n",
       "       'hue automobile', 'whats shade car', 'tell color car',\n",
       "       'whats tone vehicle', 'describe color nearby car',\n",
       "       'identify color car ahead', 'currency pocket',\n",
       "       'identify bill wallet', 'recognize money im hold',\n",
       "       'tell currency denomination', 'detect currency note im hold',\n",
       "       'whats visible vicinity', 'give rundown surround',\n",
       "       'describe whats front', 'narrate whats around',\n",
       "       'identify object nearby', 'far away near door',\n",
       "       'estimate distance door', 'calculate gap door',\n",
       "       'whats distance near door', 'measure gap door', 'read text paper',\n",
       "       'decipher text', 'convert image readable text',\n",
       "       'translate text image', 'whats write document', 'render english',\n",
       "       'change text english', 'color car nearby',\n",
       "       'describe color vehicle front', 'identify color car close',\n",
       "       'hue car front', 'whats shade car ahead',\n",
       "       'tell color nearby vehicle', 'whats tone car nearby',\n",
       "       'identify color car front', 'describe color vehicle ahead',\n",
       "       'color car close', 'currency note', 'tell currency im hold',\n",
       "       'detect denomination bill', 'whats visible current location',\n",
       "       'describe object nearby', 'narrate whats happen',\n",
       "       'identify items vicinity', 'far away door',\n",
       "       'calculate gap near door', 'whats depth close door',\n",
       "       'read text image', 'extract text picture',\n",
       "       'convert picture readable text', 'whats write image',\n",
       "       'convert english text', 'color car vicinity',\n",
       "       'describe color vehicle nearby', 'identify color car around',\n",
       "       'hue car nearby', 'whats shade vehicle close',\n",
       "       'tell color car nearby', 'whats tone car vicinity',\n",
       "       'identify color car near', 'describe color vehicle close',\n",
       "       'color car proximity', 'denomination bill',\n",
       "       'recognize currency note hand', 'tell type currency im hold',\n",
       "       'identify bill possession', 'whats view front',\n",
       "       'describe things around', 'provide detail description surround',\n",
       "       'identify object field vision',\n",
       "       'whats distance door current position',\n",
       "       'calculate distance near door', 'far close door',\n",
       "       'measure depth door', 'read text document', 'recognize text image',\n",
       "       'convert text image readable form', 'translate content image',\n",
       "       'image say', 'provide english translation text',\n",
       "       'change language text english', 'translate english language',\n",
       "       'convert text english', 'color car behind',\n",
       "       'describe color vehicle behind',\n",
       "       'identify color car situate behind', 'hue car behind',\n",
       "       'whats shade vehicle behind', 'tell color car behind',\n",
       "       'whats tone car behind', 'identify color car rear view',\n",
       "       'color car rear view', 'currency note wallet',\n",
       "       'identify currency im hold', 'tell denomination bill hand',\n",
       "       'detect type currency note im hold',\n",
       "       'whats visible immediate surround', 'describe elements nearby',\n",
       "       'narrate whats around moment',\n",
       "       'identify object immediate environment',\n",
       "       'far away door current location', 'estimate distance near door',\n",
       "       'calculate gap close door', 'whats depth door front',\n",
       "       'measure distance position door', 'read text picture',\n",
       "       'extract text image file', 'translate text within image',\n",
       "       'whats write picture', 'translate text english language',\n",
       "       'provide english translation text snippet',\n",
       "       'change language text english please', 'translate english text',\n",
       "       'convert text english language', 'color car next',\n",
       "       'describe color vehicle beside', 'identify color car adjacent',\n",
       "       'hue car beside', 'whats shade vehicle next',\n",
       "       'tell color car next', 'whats tone car next',\n",
       "       'identify color car beside', 'describe color vehicle next',\n",
       "       'color car beside', 'identify currency pocket',\n",
       "       'tell kind money im hold', 'detect denomination bill possession',\n",
       "       'whats visible current field vision',\n",
       "       'describe object within immediate vicinity',\n",
       "       'narrate whats around right', 'identify items present surround',\n",
       "       'estimate distance close door', 'whats depth door near',\n",
       "       'measure distance near door', 'read text scan document',\n",
       "       'extract text scan image', 'convert scan image text',\n",
       "       'translate text find within scan image',\n",
       "       'whats write scan document',\n",
       "       'provide english translation text excerpt', 'color car park front',\n",
       "       'describe color park vehicle', 'identify color car park nearby',\n",
       "       'hue park car', 'whats shade park vehicle',\n",
       "       'tell color car park nearby', 'whats tone park car',\n",
       "       'color park car nearby', 'recognize currency im hold',\n",
       "       'tell denomination bill', 'detect type currency note possession',\n",
       "       'describe object within vicinity', 'whats depth near door',\n",
       "       'narrate whats surround', 'measure distance current position door',\n",
       "       'describe color car ahead', 'tell color car front',\n",
       "       'whats tone car ahead', 'currency note pocket',\n",
       "       'detect type currency hand', 'identify object around',\n",
       "       'describe surround', 'narrate whats nearby', 'list items vicinity',\n",
       "       'determine depth near door', 'identify color nearby vehicle',\n",
       "       'hue car', 'whats shade vehicle', 'tell color nearby car',\n",
       "       'whats tone car', 'describe color vehicle', 'color nearby car',\n",
       "       'read text menu', 'sign say', 'extract ingredients recipe',\n",
       "       'transcribe handwritten note', 'convert document text',\n",
       "       'translate instructions spanish',\n",
       "       'give french translation article', 'turn email german',\n",
       "       'language text write', 'translate text prefer language',\n",
       "       'color chair im sit', 'identify color clothe person',\n",
       "       'tell color fruit bowl', 'describe color water glass',\n",
       "       'color carpet floor', 'value coin pocket', 'kind money',\n",
       "       'tell denomination coin', 'identify currency im carry',\n",
       "       'describe coin pocket', 'estimate distance tree',\n",
       "       'calculate distance end hallway', 'measure distance cat',\n",
       "       'far away bus stop'], dtype='<U41')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: input, label\n",
      "\n",
      "+----+--------------------------------------------------+----------------------+\n",
      "|    | input                                            | label                |\n",
      "|----+--------------------------------------------------+----------------------|\n",
      "|  0 | What currency is in my wallet?                   | currency recognition |\n",
      "|  1 | Can you tell me the currency in my palm?         | currency recognition |\n",
      "|  2 | Identify the money in my hand.                   | currency recognition |\n",
      "|  3 | What's the denomination of the bill I'm holding? | currency recognition |\n",
      "|  4 | Tell me the type of currency in my hand.         | currency recognition |\n",
      "+----+--------------------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Show the column names\n",
    "print(f\"Columns: {', '.join(dataset.columns)}\", end='\\n\\n')\n",
    "\n",
    "# Print the first 5 samples as a table\n",
    "print(tabulate(dataset.head(), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_y_train = label_encoder.fit_transform(processed_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color recognition': 0, 'currency recognition': 1, 'depth estimation': 2, 'ocr': 3, 'scene description': 4, 'translation': 5}\n"
     ]
    }
   ],
   "source": [
    "# Get the mapping of original labels to encoded values\n",
    "label_mapping = {label: encoded_label for label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n",
    "\n",
    "# Now label_mapping contains the mapping of original labels to their encoded values\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels: ['color recognition' 'currency recognition' 'depth estimation' 'ocr'\n",
      " 'scene description' 'translation']\n",
      "Encoded Values: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Get the original labels\n",
    "original_labels = label_encoder.classes_\n",
    "\n",
    "# Get the corresponding encoded values\n",
    "encoded_values = label_encoder.transform(original_labels)\n",
    "\n",
    "# Now original_labels contains the original labels and encoded_values contains their corresponding encoded values\n",
    "print(\"Original Labels:\", original_labels)\n",
    "print(\"Encoded Values:\", encoded_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Create a vectorizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(processed_X)\n",
    "joblib.dump(vectorizer, 'models/vectorizer.joblib')\n",
    "\n",
    "# Transform text to vectors\n",
    "processed_X = vectorizer.transform(processed_X).toarray()\n",
    "\n",
    "# vectorizer = CountVectorizer(ngram_range=(2),max_features=10000)\n",
    "# vectorizer.fit(processed_X)\n",
    "# joblib.dump(vectorizer, 'models/vectorizer.joblib')\n",
    "\n",
    "# # Transform text to vectors\n",
    "# X = vectorizer.transform(processed_X).toarray()\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# vectorizer.fit(processed_X)\n",
    "# joblib.dump(vectorizer, 'models/vectorizer.joblib')\n",
    "\n",
    "# # Transform text to vectors\n",
    "# X = vectorizer.transform(processed_X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Prepare train and test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_X, encoded_y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train and X_test if they are 1-dimensional arrays\n",
    "if len(X_train.shape) == 1:\n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "if len(X_test.shape) == 1:\n",
    "    X_test = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(255, 102, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>First model: Naive Bayes (MultinomialNB)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion matrix:\n",
      "                      color recognition  currency recognition  \\\n",
      "color recognition                    13                     0   \n",
      "currency recognition                  0                     7   \n",
      "depth estimation                      0                     0   \n",
      "ocr                                   0                     0   \n",
      "scene description                     1                     0   \n",
      "translation                           0                     0   \n",
      "\n",
      "                      depth estimation  ocr  scene description  translation  \n",
      "color recognition                    0    0                  0            0  \n",
      "currency recognition                 0    0                  0            0  \n",
      "depth estimation                    13    0                  0            0  \n",
      "ocr                                  0    4                  0            0  \n",
      "scene description                    0    0                  9            0  \n",
      "translation                          0    0                  0            3  \n",
      "Precision: [0.92857143 1.         1.         1.         1.         1.        ]\n",
      "Recall: [1.  1.  1.  1.  0.9 1. ]\n",
      "F1-score: [0.96296296 1.         1.         1.         0.94736842 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "NB_y_pred = NB_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "NB_accuracy = accuracy_score(y_test, NB_y_pred)\n",
    "print('Accuracy:', NB_accuracy)\n",
    "\n",
    "# Print the confusion matrix of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, NB_y_pred)\n",
    "print('Confusion matrix:')\n",
    "index = original_labels\n",
    "print(pd.DataFrame(conf_matrix,index=index,columns=index))\n",
    "\n",
    "# Calculate precision, recall, and F1-score of the classifier\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, NB_y_pred)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(255, 102, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Second model: Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "RF_model = RandomForestClassifier(n_estimators=100,\n",
    "                                  max_depth=10,\n",
    "                                  random_state=42)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Confusion matrix:\n",
      "                      color recognition  currency recognition  \\\n",
      "color recognition                    13                     0   \n",
      "currency recognition                  0                     6   \n",
      "depth estimation                      0                     0   \n",
      "ocr                                   0                     0   \n",
      "scene description                     0                     0   \n",
      "translation                           0                     0   \n",
      "\n",
      "                      depth estimation  ocr  scene description  translation  \n",
      "color recognition                    0    0                  0            0  \n",
      "currency recognition                 0    0                  1            0  \n",
      "depth estimation                    13    0                  0            0  \n",
      "ocr                                  0    4                  0            0  \n",
      "scene description                    0    0                 10            0  \n",
      "translation                          0    1                  0            2  \n",
      "Precision: [1.         1.         1.         0.8        0.90909091 1.        ]\n",
      "Recall: [1.         0.85714286 1.         1.         1.         0.66666667]\n",
      "F1-score: [1.         0.92307692 1.         0.88888889 0.95238095 0.8       ]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "RF_y_pred = RF_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "RF_accuracy = accuracy_score(y_test, RF_y_pred)\n",
    "print('Accuracy:', RF_accuracy)\n",
    "\n",
    "# Print the confusion matrix of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, RF_y_pred)\n",
    "print('Confusion matrix:')\n",
    "index = original_labels\n",
    "print(pd.DataFrame(conf_matrix,index=index,columns=index))\n",
    "\n",
    "# Calculate precision, recall, and F1-score of the classifier\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, RF_y_pred)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(255, 102, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Third model: K-Nearest Neighbors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Confusion matrix:\n",
      "                      color recognition  currency recognition  \\\n",
      "color recognition                    13                     0   \n",
      "currency recognition                  0                     7   \n",
      "depth estimation                      0                     0   \n",
      "ocr                                   0                     0   \n",
      "scene description                     1                     0   \n",
      "translation                           0                     0   \n",
      "\n",
      "                      depth estimation  ocr  scene description  translation  \n",
      "color recognition                    0    0                  0            0  \n",
      "currency recognition                 0    0                  0            0  \n",
      "depth estimation                    13    0                  0            0  \n",
      "ocr                                  0    3                  0            1  \n",
      "scene description                    0    1                  8            0  \n",
      "translation                          0    0                  0            3  \n",
      "Precision: [0.92857143 1.         1.         0.75       1.         0.75      ]\n",
      "Recall: [1.   1.   1.   0.75 0.8  1.  ]\n",
      "F1-score: [0.96296296 1.         1.         0.75       0.88888889 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "KNN_y_pred = KNN_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "KNN_accuracy = accuracy_score(y_test, KNN_y_pred)\n",
    "print('Accuracy:', KNN_accuracy)\n",
    "\n",
    "# Print the confusion matrix of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, KNN_y_pred)\n",
    "print('Confusion matrix:')\n",
    "index = original_labels\n",
    "print(pd.DataFrame(conf_matrix,index=index,columns=index))\n",
    "\n",
    "# Calculate precision, recall, and F1-score of the classifier\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, KNN_y_pred)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(255, 102, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Fourth model: Support Vector Machine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "SVM_model = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion matrix:\n",
      "                      color recognition  currency recognition  \\\n",
      "color recognition                    13                     0   \n",
      "currency recognition                  0                     7   \n",
      "depth estimation                      0                     0   \n",
      "ocr                                   0                     0   \n",
      "scene description                     0                     0   \n",
      "translation                           0                     0   \n",
      "\n",
      "                      depth estimation  ocr  scene description  translation  \n",
      "color recognition                    0    0                  0            0  \n",
      "currency recognition                 0    0                  0            0  \n",
      "depth estimation                    13    0                  0            0  \n",
      "ocr                                  0    4                  0            0  \n",
      "scene description                    0    0                 10            0  \n",
      "translation                          0    1                  0            2  \n",
      "Precision: [1.  1.  1.  0.8 1.  1. ]\n",
      "Recall: [1.         1.         1.         1.         1.         0.66666667]\n",
      "F1-score: [1.         1.         1.         0.88888889 1.         0.8       ]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "SVM_y_pred = SVM_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "SVM_accuracy = accuracy_score(y_test, SVM_y_pred)\n",
    "print('Accuracy:', SVM_accuracy)\n",
    "\n",
    "# Print the confusion matrix of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, SVM_y_pred)\n",
    "print('Confusion matrix:')\n",
    "index = original_labels\n",
    "print(pd.DataFrame(conf_matrix,index=index,columns=index))\n",
    "\n",
    "# Calculate precision, recall, and F1-score of the classifier\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, SVM_y_pred)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(255, 102, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Fifth model: Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "LR_model = LogisticRegression(random_state=42)\n",
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(86, 180, 252);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion matrix:\n",
      "                      color recognition  currency recognition  \\\n",
      "color recognition                    13                     0   \n",
      "currency recognition                  0                     7   \n",
      "depth estimation                      0                     0   \n",
      "ocr                                   0                     0   \n",
      "scene description                     0                     0   \n",
      "translation                           0                     0   \n",
      "\n",
      "                      depth estimation  ocr  scene description  translation  \n",
      "color recognition                    0    0                  0            0  \n",
      "currency recognition                 0    0                  0            0  \n",
      "depth estimation                    13    0                  0            0  \n",
      "ocr                                  0    4                  0            0  \n",
      "scene description                    0    0                 10            0  \n",
      "translation                          0    1                  0            2  \n",
      "Precision: [1.  1.  1.  0.8 1.  1. ]\n",
      "Recall: [1.         1.         1.         1.         1.         0.66666667]\n",
      "F1-score: [1.         1.         1.         0.88888889 1.         0.8       ]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "LR_y_pred = LR_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "LR_accuracy = accuracy_score(y_test, LR_y_pred)\n",
    "print('Accuracy:', LR_accuracy)\n",
    "\n",
    "# Print the confusion matrix of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, LR_y_pred)\n",
    "print('Confusion matrix:')\n",
    "index = original_labels\n",
    "print(pd.DataFrame(conf_matrix,index=index,columns=index))\n",
    "\n",
    "# Calculate precision, recall, and F1-score of the classifier\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, LR_y_pred)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3{\n",
    "        color: rgb(0, 255, 0);\n",
    "        margin: 0;\n",
    "    }\n",
    "</style>\n",
    "<h3>Compare between models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar plot to compare the accuracy scores\n",
    "labels = [\n",
    "    'Naive Bayes', 'Random Forest', 'K-Nearest Neighbors',\n",
    "    'Support Vector Machine', 'Logistic Regression'\n",
    "]\n",
    "\n",
    "accuracy_scores = [0.91, 0.89, 0.93, 0.88, 0.78]\n",
    "# accuracy_scores = [NB_accuracy, RF_accuracy, KNN_accuracy, SVM_accuracy, LR_accuracy]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.bar(labels, accuracy_scores)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Classifier Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "final_model = NB_model\n",
    "joblib.dump(final_model, 'models/sentimental-analysis-model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
